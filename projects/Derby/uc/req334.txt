[DERBY-3729] Error message is rather unrevealing when creating large databases on FAT32 drives <p>I was creating a test database on an external USB drive formatted as FAT32- it contains some tables that have quite large binary objects in: This was in conjunction with Hibernate. I got this rather cryptic error message.</p>

<p>Looks rather scary:</p>

<p>18:02:37,550  WARN JDBCExceptionReporter:77 - SQL Error: 40000, SQLState: 08006<br/>
18:02:37,550 ERROR JDBCExceptionReporter:78 - A network protocol error was encountered and the connection has been terminated: the requested command encountered an unarchitected and implementation-specific condition for which there was no architected message<br/>
18:02:37,597 ERROR AbstractFlushingEventListener:301 - Could not synchronize database state with session<br/>
org.hibernate.exception.JDBCConnectionException: could not insert: <span class= error >&#91;proteinChainMoleculeBinaryData&#93;</span><br/>
        at org.hibernate.exception.SQLStateConverter.convert(SQLStateConverter.java:74)<br/>
        at org.hibernate.exception.JDBCExceptionHelper.convert(JDBCExceptionHelper.java:43)<br/>
        at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.<br/>
java:2263)<br/>
        at org.hibernate.persister.entity.AbstractEntityPersister.insert(AbstractEntityPersister.java:2656)<br/>
        at org.hibernate.action.EntityInsertAction.execute(EntityInsertAction.java:52)<br/>
        at org.hibernate.engine.ActionQueue.execute(ActionQueue.java:248)<br/>
        at org.hibernate.engine.ActionQueue.executeActions(ActionQueue.java:232)<br/>
        at org.hibernate.engine.ActionQueue.executeActions(ActionQueue.java:139)<br/>
        at org.hibernate.event.def.AbstractFlushingEventListener.performExecutions(AbstractFlushingEventListener.java:298)<br/>
        at org.hibernate.event.def.DefaultFlushEventListener.onFlush(DefaultFlushEventListener.java:27)<br/>
        at org.hibernate.impl.SessionImpl.flush(SessionImpl.java:1000)<br/>
        at org.hibernate.impl.SessionImpl.managedFlush(SessionImpl.java:338)<br/>
        at org.hibernate.transaction.JDBCTransaction.commit(JDBCTransaction.java:106)</p>

<p>Initially it didnt even occur to me that this may be due to me using a FAT32 drive, but eventually I figured out that the table s file had got to the operating FAT32 limit: I had a file of 4,194,272 KB.</p>

<p>In the derby log, there s a more revealing, but still incorrect, error message:</p>

<p>ERROR XSDG1: Page Page(131071,Container(0, 2384)) could not be written to disk, please check if disk is full.<br/>
	at org.apache.derby.iapi.error.StandardException.newException(Unknown Source)<br/>
	at org.apache.derby.impl.store.raw.data.CachedPage.writePage(Unknown Source)<br/>
	at org.apache.derby.impl.store.raw.data.CachedPage.createIdentity(Unknown Source)<br/>
	at org.apache.derby.impl.services.cache.CachedItem.takeOnIdentity(Unknown Source)<br/>
	at org.apache.derby.impl.services.cache.Clock.addEntry(Unknown Source)<br/>
	at org.apache.derby.impl.services.cache.Clock.create(Unknown Source)<br/>
	at org.apache.derby.impl.store.raw.data.FileContainer.initPage(Unknown Source)<br/>
	at org.apache.derby.impl.store.raw.data.FileContainer.newPage(Unknown Source)<br/>
	at org.apache.derby.impl.store.raw.data.BaseContainer.addPage(Unknown Source)<br/>
	at org.apache.derby.impl.store.raw.data.StoredPage.getNewOverflowPage(Unknown Source)<br/>
	at org.apache.derby.impl.store.raw.data.BasePage.insertLongColumn(Unknown Source)<br/>
	at org.apache.derby.impl.store.raw.data.BasePage.insertAllowOverflow(Unknown Source)<br/>
	at org.apache.derby.impl.store.raw.data.BasePage.insert(Unknown Source)<br/>
	at org.apache.derby.impl.store.access.heap.HeapController.doInsert(Unknown Source)<br/>
	at org.apache.derby.impl.store.access.heap.HeapController.insertAndFetchLocation(Unknown Source)<br/>
	at org.apache.derby.impl.sql.execute.RowChangerImpl.insertRow(Unknown Source)<br/>
	at org.apache.derby.impl.sql.execute.InsertResultSet.normalInsertCore(Unknown Source)<br/>
	at org.apache.derby.impl.sql.execute.InsertResultSet.open(Unknown Source)<br/>
	at org.apache.derby.impl.sql.GenericPreparedStatement.execute(Unknown Source)<br/>
	at org.apache.derby.impl.jdbc.EmbedStatement.executeStatement(Unknown Source)<br/>
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.executeStatement(Unknown Source)<br/>
	at org.apache.derby.impl.jdbc.EmbedPreparedStatement.execute(Unknown Source)<br/>
	at org.apache.derby.impl.drda.DRDAStatement.execute(Unknown Source)<br/>
	at org.apache.derby.impl.drda.DRDAConnThread.parseEXCSQLSTTobjects(Unknown Source)<br/>
	at org.apache.derby.impl.drda.DRDAConnThread.parseEXCSQLSTT(Unknown Source)<br/>
	at org.apache.derby.impl.drda.DRDAConnThread.processCommands(Unknown Source)<br/>
	at org.apache.derby.impl.drda.DRDAConnThread.run(Unknown Source)<br/>
Caused by: java.io.IOException: There is not enough space on the disk<br/>
	at sun.nio.ch.FileDispatcher.pwrite0(Native Method)<br/>
	at sun.nio.ch.FileDispatcher.pwrite(FileDispatcher.java:51)<br/>
	at sun.nio.ch.IOUtil.writeFromNativeBuffer(IOUtil.java:100)<br/>
	at sun.nio.ch.IOUtil.write(IOUtil.java:75)<br/>
	at sun.nio.ch.FileChannelImpl.write(FileChannelImpl.java:651)<br/>
	at org.apache.derby.impl.store.raw.data.RAFContainer4.writeFull(Unknown Source)<br/>
	at org.apache.derby.impl.store.raw.data.RAFContainer4.writePage0(Unknown Source)<br/>
	at org.apache.derby.impl.store.raw.data.RAFContainer4.writePage(Unknown Source)<br/>
	... 26 more</p>

<p>The error is still strictly speaking incorrect - my disk is far from full, but I have created a file too big for the disk type - but the error is at least closer to the truth and this would be useful information for the derby client to display rather than the rather scary looking message I was getting.</p>